## 任务
#### 总目标：实现一个能识别多种模态输入中风险内容的平台(的demo)

#### 核心问题：
* 怎么测试，以什么指标呈现我们的效果？ 
* Demo要呈现什么样的内容？ 
* 大模型在其中起到了什么样的作用?
  
<br>

#### 任务1：诈骗短信文本分类 + 风险点抽取
任务描述：识别文本是否存在风险，是否归属于某类风险，以及风险对应的词句\
输入：短信文本 \
输出1：每种风险的存在的概率（可以做n分类，也可以做n个二分类）\
输出2：识别风险的依据词语（如"点击链接")\
<br>
**示例：** \
输入：您好，这里是中国邮政，您的包裹需要补交税费，请提供银行卡信息进行支付。\
输出：
1. 风险点：["提供银行卡信息"]
2. 是否有风险：1(有风险)
3. 风险类别：6(风险类别为第6类)
<br>    

任务难点：数据准备
* 目前已有第三人称的案件描述数据集（约10万条），如何利用LLM重写为第一人称的短信文本，并保证短信文本的真实性（不要机里机气）、多样性（避免模型学习语言模式本身）
* 目前的数据全部都是正例（有风险短信），如何获取一定比例的负例（即无风险、正常的短信），并保证与正例在语言模式上相似。


方案：
* 数据准备：主要通过调GPT4/Deepseek的API + 设计Prompt模板来生成测试数据(基于CCL 2024 EVAL6数据集)
* 抽取：本地LLM（考虑微调） + 任务指令
* 分类：本地LLM（考虑微调） + 任务指令，也可以尝试用embedding模型或使用LLM的中间层表征 + 自己训练一个分类层来实现
* 考虑使用RAG，便于服务端快速更新新型诈骗案例

相关资料：
* train.json / test.json
* openai/deepseek api文档 (用于调用LLM生成数据)
* AttrPrompt: https://arxiv.org/abs/2306.15895 (用于提升生成数据多样性)

<br>

#### 任务2：换脸视频识别（+ 色情暴力等其他风险点）
任务描述：识别视频是否使用了换脸技术(Deepfake)，也可以对其他内容（如暴力、色情做出判断），如果能对风险内容出现时间点做出标注更好。

方案：
* 直接选一个deepfake detection相关的开源方案跑通
* Video-LLAVA / Video-Chat 部署在本地，用于直接抽取视频中的风险点及其时间点，以及生成视频caption接入任务1 pipeline

相关资料：
* Deepfake Generation and Detection: A Benchmark and Survey https://arxiv.org/abs/2403.17881
去里面找找能用来做Demo的数据和有开源代码，容易部署的项目

* Video-LLAVA: https://github.com/PKU-YuanGroup/Video-LLaVA

<br>

#### 任务3：音频风险识别
任务描述：判定音频是否为合成的，并对其内容本身做风险点抽取、识别 \
方案：
* 音频合成问题单独做，找开源代码跑通
* 可将文本转文字后将文字送入LLM做风险点抽取、识别
* 也可以将转换后的文本连同音频一起送入多模态大模型，做风险点抽取、识别

<br>

#### 任务4：合成图片识别
任务描述：对于富文本图片，与任务1相似；对于其他类型的图片，与任务2相似（换脸+其他风险点）\
方案：
* OCR模型 $\rightarrow$ 任务1 pipeline
* 使用LLaVA

<br>

#### TODO
- [x] videoLLaVA本地运行
- [x] LLama3-chat-chinese本地运行
- [x] deepseek API调用 

- [ ] 完成TextPipeline中RAG系统的搭建（任务一）
- [ ] 设计prompt模板，调用GPT4/Deepseek将CCL 2024 EVAL6提供的数据集（重新划分一个大一点的测试集）从脱敏案例描述转为模拟诈骗信息，用于测试（任务一）
- [ ] 确定让模型完成风险识别任务的示例模板（所有任务）
- [ ] 确定各任务所需的测试数据及测试指标，搭建测试管线（所有任务）


